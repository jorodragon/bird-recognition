{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 18:47:47.168226: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import efficientnet.tfkeras as efn  # Convolutional Neural Network architecture\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = (224, 224)\n",
    "BIRDS = [\n",
    "    \"0se\",\n",
    "    \"1hoang-yen\",\n",
    "    \"2hoa-mi\",\n",
    "    \"3tri\",\n",
    "    \"4trich-co\",\n",
    "    \"5hoet-lua\",\n",
    "    \"6le-le\",\n",
    "    \"7sao-nau\",\n",
    "    \"9chich-choe\",\n",
    "    \"8cu-dat\",\n",
    "    \"10cong-coc\",\n",
    "    \"11ca-cuong\",\n",
    "    \"12co\",\n",
    "    \"13quoc\",\n",
    "    \"14hec-xoan\",\n",
    "    \"15hoet-den\",\n",
    "    \"16phuong-hoang-dat\",\n",
    "    \"17oanh\",\n",
    "    \"18huyt-co\",\n",
    "    \"19khuou\",\n",
    "    \"20trich-re\",\n",
    "    \"21chang-nghich\",\n",
    "    \"22mo-nhat\",\n",
    "    \"23de-giun\",\n",
    "    \"24khuyen\",\n",
    "    \"25bim-bip\",\n",
    "    \"26chao-mao\",\n",
    "    \"27hut-mat\",\n",
    "    \"28cheo-beo\",\n",
    "    \"29cut\",\n",
    "    \"30sau\",\n",
    "    \"31cum-num\",\n",
    "    \"32thanh-lam\",\n",
    "    \"33bo-cau\",\n",
    "    \"34choc-quach\",\n",
    "    \"35que-lam\",\n",
    "    \"36ngu-sac\",\n",
    "    \"37hoanh-hoach\",\n",
    "    \"38en\",\n",
    "    \"39thanh-tuoc\",\n",
    "    \"40vac\",\n",
    "    \"41chia-voi\",\n",
    "    \"42mat-xeo\",\n",
    "    \"43mat-do\",\n",
    "    \"44sam-cam\",\n",
    "    \"45cu-gay\",\n",
    "    \"46ket\",\n",
    "    \"47trao-trao\",\n",
    "    \"48xanh-tim\",\n",
    "]\n",
    "DATA_PATH = \"/Volumes/MacDATA/LEARNING/thesis/bird-recognition/core-ai/data/full-data/\"\n",
    "BATCH_SIZE = 16\n",
    "MODEL_PATH = \"/Volumes/MacDATA/LEARNING/thesis/bird-recognition/core-ai/models/mobilenet.h5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12390 images belonging to 49 classes.\n",
      "Found 1530 images belonging to 49 classes.\n",
      "Found 1600 images belonging to 49 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "train_batches = train_datagen.flow_from_directory(\n",
    "    DATA_PATH + \"train\",\n",
    "    classes=BIRDS,\n",
    "    target_size=IM_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "valid_batches = valid_datagen.flow_from_directory(\n",
    "    DATA_PATH + \"val\",\n",
    "    classes=BIRDS,\n",
    "    target_size=IM_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_batches = test_datagen.flow_from_directory(\n",
    "    DATA_PATH + \"test\",\n",
    "    classes=BIRDS,\n",
    "    target_size=IM_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 18:47:52.137025: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define CNN's architecture\n",
    "net = MobileNetV2(include_top=False,\n",
    "                  weights='imagenet',\n",
    "                  input_tensor=None,\n",
    "                  input_shape=(224, 224, 3))\n",
    "x = net.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(len(BIRDS), activation=\"softmax\", name=\"softmax\")(x)\n",
    "net_final = Model(inputs=net.input, outputs=output_layer)\n",
    "net_final.compile(\n",
    "    optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# print(net_final.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate class weights for unbalanced dataset\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    \"balanced\", classes=np.unique(train_batches.classes), y=train_batches.classes\n",
    ")\n",
    "\n",
    "class_weights = {i:w for i,w in enumerate(class_weights)}\n",
    "\n",
    "# Define callbacks\n",
    "ModelCheck = ModelCheckpoint(\n",
    "    MODEL_PATH,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"auto\",\n",
    ")\n",
    "\n",
    "ReduceLR = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2, patience=5, min_lr=3e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "775/775 [==============================] - 1002s 1s/step - loss: 5.8501 - accuracy: 0.0643 - val_loss: 55.8847 - val_accuracy: 0.0536 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "775/775 [==============================] - 914s 1s/step - loss: 4.8397 - accuracy: 0.0413 - val_loss: 104.3001 - val_accuracy: 0.0634 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "775/775 [==============================] - 912s 1s/step - loss: 4.3027 - accuracy: 0.0447 - val_loss: 44.0636 - val_accuracy: 0.0824 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "775/775 [==============================] - 919s 1s/step - loss: 3.9830 - accuracy: 0.0834 - val_loss: 87.1635 - val_accuracy: 0.0451 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "775/775 [==============================] - 919s 1s/step - loss: 3.4718 - accuracy: 0.1099 - val_loss: 19.2196 - val_accuracy: 0.1046 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "775/775 [==============================] - 934s 1s/step - loss: 3.0754 - accuracy: 0.1472 - val_loss: 17.1719 - val_accuracy: 0.1222 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "775/775 [==============================] - 940s 1s/step - loss: 3.1464 - accuracy: 0.1525 - val_loss: 30.7000 - val_accuracy: 0.0856 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "775/775 [==============================] - 938s 1s/step - loss: 2.7665 - accuracy: 0.1853 - val_loss: 18.1854 - val_accuracy: 0.1150 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "775/775 [==============================] - 935s 1s/step - loss: 2.5234 - accuracy: 0.2321 - val_loss: 18.4753 - val_accuracy: 0.1111 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "775/775 [==============================] - 934s 1s/step - loss: 2.3251 - accuracy: 0.2671 - val_loss: 9.9754 - val_accuracy: 0.0444 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "775/775 [==============================] - 935s 1s/step - loss: 2.1062 - accuracy: 0.3215 - val_loss: 10.1000 - val_accuracy: 0.0294 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "775/775 [==============================] - 937s 1s/step - loss: 1.9310 - accuracy: 0.3606 - val_loss: 11.3857 - val_accuracy: 0.0667 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "775/775 [==============================] - 935s 1s/step - loss: 1.8513 - accuracy: 0.3775 - val_loss: 8.8305 - val_accuracy: 0.0627 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "775/775 [==============================] - 935s 1s/step - loss: 1.6735 - accuracy: 0.4230 - val_loss: 8.0406 - val_accuracy: 0.1059 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "775/775 [==============================] - 935s 1s/step - loss: 1.5124 - accuracy: 0.4611 - val_loss: 7.0578 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "775/775 [==============================] - 929s 1s/step - loss: 1.5187 - accuracy: 0.4743 - val_loss: 9.0571 - val_accuracy: 0.2124 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "775/775 [==============================] - 927s 1s/step - loss: 1.3702 - accuracy: 0.5061 - val_loss: 3.8972 - val_accuracy: 0.4020 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "775/775 [==============================] - 944s 1s/step - loss: 1.3272 - accuracy: 0.5245 - val_loss: 8.7735 - val_accuracy: 0.1209 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "775/775 [==============================] - 1096s 1s/step - loss: 1.2211 - accuracy: 0.5482 - val_loss: 9.4447 - val_accuracy: 0.2268 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "775/775 [==============================] - 962s 1s/step - loss: 1.1339 - accuracy: 0.5742 - val_loss: 6.1641 - val_accuracy: 0.4425 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "775/775 [==============================] - 968s 1s/step - loss: 1.0522 - accuracy: 0.6044 - val_loss: 3.9776 - val_accuracy: 0.4399 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "775/775 [==============================] - 854s 1s/step - loss: 1.0129 - accuracy: 0.6049 - val_loss: 4.7150 - val_accuracy: 0.3536 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "775/775 [==============================] - 842s 1s/step - loss: 0.8152 - accuracy: 0.6688 - val_loss: 2.1612 - val_accuracy: 0.5026 - lr: 3.0000e-04\n",
      "Epoch 24/30\n",
      "775/775 [==============================] - 838s 1s/step - loss: 0.6944 - accuracy: 0.7023 - val_loss: 0.9926 - val_accuracy: 0.7144 - lr: 3.0000e-04\n",
      "Epoch 25/30\n",
      "775/775 [==============================] - 838s 1s/step - loss: 0.6919 - accuracy: 0.7069 - val_loss: 0.6415 - val_accuracy: 0.7935 - lr: 3.0000e-04\n",
      "Epoch 26/30\n",
      "775/775 [==============================] - 838s 1s/step - loss: 0.6697 - accuracy: 0.7199 - val_loss: 0.7522 - val_accuracy: 0.7418 - lr: 3.0000e-04\n",
      "Epoch 27/30\n",
      "775/775 [==============================] - 838s 1s/step - loss: 0.6338 - accuracy: 0.7322 - val_loss: 0.6123 - val_accuracy: 0.7948 - lr: 3.0000e-04\n",
      "Epoch 28/30\n",
      "775/775 [==============================] - 841s 1s/step - loss: 0.6102 - accuracy: 0.7403 - val_loss: 0.5855 - val_accuracy: 0.8039 - lr: 3.0000e-04\n",
      "Epoch 29/30\n",
      "775/775 [==============================] - 840s 1s/step - loss: 0.6120 - accuracy: 0.7375 - val_loss: 0.5040 - val_accuracy: 0.8464 - lr: 3.0000e-04\n",
      "Epoch 30/30\n",
      "775/775 [==============================] - 840s 1s/step - loss: 0.5795 - accuracy: 0.7518 - val_loss: 0.7503 - val_accuracy: 0.7627 - lr: 3.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1473882e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "net_final.fit(\n",
    "    train_batches,\n",
    "    validation_data=valid_batches,\n",
    "    epochs=30,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[ModelCheck, ReduceLR],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************\n",
      "Class nr  0  ->  0se\n",
      "Class nr  1  ->  1hoang-yen\n",
      "Class nr  2  ->  2hoa-mi\n",
      "Class nr  3  ->  3tri\n",
      "Class nr  4  ->  4trich-co\n",
      "Class nr  5  ->  5hoet-lua\n",
      "Class nr  6  ->  6le-le\n",
      "Class nr  7  ->  7sao-nau\n",
      "Class nr  8  ->  9chich-choe\n",
      "Class nr  9  ->  8cu-dat\n",
      "Class nr  10  ->  10cong-coc\n",
      "Class nr  11  ->  11ca-cuong\n",
      "Class nr  12  ->  12co\n",
      "Class nr  13  ->  13quoc\n",
      "Class nr  14  ->  14hec-xoan\n",
      "Class nr  15  ->  15hoet-den\n",
      "Class nr  16  ->  16phuong-hoang-dat\n",
      "Class nr  17  ->  17oanh\n",
      "Class nr  18  ->  18huyt-co\n",
      "Class nr  19  ->  19khuou\n",
      "Class nr  20  ->  20trich-re\n",
      "Class nr  21  ->  21chang-nghich\n",
      "Class nr  22  ->  22mo-nhat\n",
      "Class nr  23  ->  23de-giun\n",
      "Class nr  24  ->  24khuyen\n",
      "Class nr  25  ->  25bim-bip\n",
      "Class nr  26  ->  26chao-mao\n",
      "Class nr  27  ->  27hut-mat\n",
      "Class nr  28  ->  28cheo-beo\n",
      "Class nr  29  ->  29cut\n",
      "Class nr  30  ->  30sau\n",
      "Class nr  31  ->  31cum-num\n",
      "Class nr  32  ->  32thanh-lam\n",
      "Class nr  33  ->  33bo-cau\n",
      "Class nr  34  ->  34choc-quach\n",
      "Class nr  35  ->  35que-lam\n",
      "Class nr  36  ->  36ngu-sac\n",
      "Class nr  37  ->  37hoanh-hoach\n",
      "Class nr  38  ->  38en\n",
      "Class nr  39  ->  39thanh-tuoc\n",
      "Class nr  40  ->  40vac\n",
      "Class nr  41  ->  41chia-voi\n",
      "Class nr  42  ->  42mat-xeo\n",
      "Class nr  43  ->  43mat-do\n",
      "Class nr  44  ->  44sam-cam\n",
      "Class nr  45  ->  45cu-gay\n",
      "Class nr  46  ->  46ket\n",
      "Class nr  47  ->  47trao-trao\n",
      "Class nr  48  ->  48xanh-tim\n",
      "****************\n",
      "accuracy: 85.44%\n",
      "100/100 [==============================] - 21s 203ms/step\n",
      "Confusion Matrix\n",
      "[[84  0  0 ...  0  0  0]\n",
      " [ 0 16  0 ...  0  0  0]\n",
      " [ 0  0 39 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 11  0  0]\n",
      " [ 0  0  0 ...  0 42  0]\n",
      " [ 0  0  0 ...  0  0 17]]\n",
      "Classification Report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               0se       0.97      1.00      0.98        84\n",
      "        1hoang-yen       0.53      0.89      0.67        18\n",
      "           2hoa-mi       0.71      0.71      0.71        55\n",
      "              3tri       0.54      1.00      0.70        13\n",
      "         4trich-co       0.67      0.89      0.76        18\n",
      "         5hoet-lua       0.64      0.47      0.55        19\n",
      "            6le-le       0.94      1.00      0.97        16\n",
      "          7sao-nau       0.70      0.82      0.75        28\n",
      "       9chich-choe       0.89      0.73      0.80        81\n",
      "           8cu-dat       0.93      0.93      0.93        28\n",
      "        10cong-coc       0.42      0.91      0.57        11\n",
      "        11ca-cuong       1.00      1.00      1.00        10\n",
      "              12co       0.64      0.27      0.38        26\n",
      "            13quoc       0.93      0.96      0.94        52\n",
      "        14hec-xoan       0.90      1.00      0.95        18\n",
      "        15hoet-den       0.58      1.00      0.74        28\n",
      "16phuong-hoang-dat       0.89      1.00      0.94        16\n",
      "            17oanh       0.90      1.00      0.95        19\n",
      "         18huyt-co       0.56      1.00      0.72        18\n",
      "           19khuou       0.93      0.86      0.90        95\n",
      "        20trich-re       0.95      0.96      0.95        55\n",
      "    21chang-nghich       1.00      1.00      1.00        12\n",
      "         22mo-nhat       0.86      1.00      0.93        19\n",
      "         23de-giun       0.91      0.91      0.91        54\n",
      "          24khuyen       0.73      0.87      0.79        52\n",
      "         25bim-bip       0.98      0.69      0.81        68\n",
      "        26chao-mao       0.90      0.80      0.85       133\n",
      "         27hut-mat       1.00      0.85      0.92        26\n",
      "        28cheo-beo       0.89      1.00      0.94        25\n",
      "             29cut       0.96      0.92      0.94        74\n",
      "             30sau       0.95      0.93      0.94        45\n",
      "         31cum-num       1.00      1.00      1.00        14\n",
      "       32thanh-lam       1.00      1.00      1.00        15\n",
      "          33bo-cau       0.67      0.91      0.77        11\n",
      "      34choc-quach       0.58      1.00      0.73        11\n",
      "         35que-lam       0.79      1.00      0.88        11\n",
      "         36ngu-sac       1.00      0.85      0.92        13\n",
      "     37hoanh-hoach       0.67      0.57      0.62        14\n",
      "              38en       0.87      0.27      0.41        74\n",
      "      39thanh-tuoc       0.79      1.00      0.88        19\n",
      "             40vac       0.86      1.00      0.92        18\n",
      "        41chia-voi       0.90      1.00      0.95         9\n",
      "         42mat-xeo       1.00      1.00      1.00        18\n",
      "          43mat-do       0.95      1.00      0.97        18\n",
      "         44sam-cam       1.00      1.00      1.00        18\n",
      "          45cu-gay       0.98      1.00      0.99        49\n",
      "             46ket       1.00      1.00      1.00        11\n",
      "       47trao-trao       1.00      0.98      0.99        43\n",
      "        48xanh-tim       0.77      0.94      0.85        18\n",
      "\n",
      "          accuracy                           0.85      1600\n",
      "         macro avg       0.84      0.90      0.85      1600\n",
      "      weighted avg       0.87      0.85      0.85      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show class indices\n",
    "print('****************')\n",
    "for cls, idx in test_batches.class_indices.items():\n",
    "    print('Class nr ',idx,' -> ', cls)\n",
    "print('****************')\n",
    "\n",
    "loaded_model = Model(inputs=net.input, outputs=output_layer)\n",
    "\n",
    "loaded_model.load_weights(MODEL_PATH)\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(optimizer=Adam(learning_rate=5e-5),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                  \n",
    "score = loaded_model.evaluate(test_batches, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "Y_pred = loaded_model.predict(test_batches)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_batches.classes, y_pred))\n",
    "print('Classification Report')\n",
    "print(classification_report(test_batches.classes, y_pred, target_names=BIRDS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
